{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e776603b",
   "metadata": {},
   "source": [
    "# Generative Adversarial Networks (GANs)\n",
    "\n",
    "This notebook is a Pytorch implementation of the GAN architecture proposed in the [paper](https://arxiv.org/pdf/1406.2661) by Goodfellow et. al. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c2329f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d87d5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_epochs = 100\n",
    "noise_dim = 100\n",
    "batch_size = 64\n",
    "learning_rate = 0.0002\n",
    "beta1 = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32fb04ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class G(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(G, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 256),\n",
    "            nn.BatchNorm1d(256),    \n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(256, 512),    \n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(512, output_dim),\n",
    "            nn.Tanh()                \n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.model(z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40d388cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class D(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(D, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 256), # fc layer\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9dec1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss() # the paper specifies the Binary Cross Entropy loss to be used and hence we set that up\n",
    "\n",
    "# we shall the use the MNIST handwritten digits dataset for training the GAN, and we know the dimensions of the image of the MNIST dataset is 28x28, which is 784 pixels in total\n",
    "# hence we set the input and output dimensions of the generator and discriminator accordingly\n",
    "\n",
    "G_model = G(input_dim=100, output_dim=784).to(device)  # Example: 100-dim noise, 28x28 image\n",
    "D_model = D(input_dim=784).to(device)  # Example: 28x28 image flattened to 784\n",
    "\n",
    "lr = 0.0002 # learning rate for both generator and discriminator\n",
    "\n",
    "# we shall use the adam optimizer for both the generator and discriminator, as it is a popular choice for training GANs\n",
    "G_optimizer = torch.optim.Adam(G_model.parameters(), lr=lr)\n",
    "D_optimizer = torch.optim.Adam(D_model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "29bc9f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "\n",
    "full_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "\n",
    "\n",
    "train_size = int(0.9 * len(full_dataset))  # e.g., 90% for training\n",
    "test_size = len(full_dataset) - train_size  # 10% for test/eval\n",
    "\n",
    "\n",
    "train_dataset, test_dataset = random_split(full_dataset, [train_size, test_size])\n",
    "\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad2d744c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100] | D Loss: 0.3757 | G Loss: 3.2945\n",
      "Epoch [2/100] | D Loss: 0.4758 | G Loss: 3.1871\n",
      "Epoch [3/100] | D Loss: 0.6277 | G Loss: 2.0811\n",
      "Epoch [4/100] | D Loss: 0.7854 | G Loss: 2.2312\n",
      "Epoch [5/100] | D Loss: 0.6549 | G Loss: 1.9531\n",
      "Epoch [6/100] | D Loss: 0.5383 | G Loss: 2.3253\n",
      "Epoch [7/100] | D Loss: 0.5024 | G Loss: 2.8170\n",
      "Epoch [8/100] | D Loss: 0.5260 | G Loss: 2.5227\n",
      "Epoch [9/100] | D Loss: 0.5878 | G Loss: 2.7396\n",
      "Epoch [10/100] | D Loss: 0.5252 | G Loss: 2.4311\n",
      "Epoch [11/100] | D Loss: 0.5736 | G Loss: 2.7149\n",
      "Epoch [12/100] | D Loss: 0.6390 | G Loss: 2.4957\n",
      "Epoch [13/100] | D Loss: 0.6162 | G Loss: 2.6829\n",
      "Epoch [14/100] | D Loss: 0.5744 | G Loss: 2.7442\n",
      "Epoch [15/100] | D Loss: 0.5828 | G Loss: 2.5803\n",
      "Epoch [16/100] | D Loss: 0.6027 | G Loss: 2.7863\n",
      "Epoch [17/100] | D Loss: 0.6306 | G Loss: 3.0010\n",
      "Epoch [18/100] | D Loss: 0.5714 | G Loss: 2.6523\n",
      "Epoch [19/100] | D Loss: 0.4654 | G Loss: 3.2270\n",
      "Epoch [20/100] | D Loss: 0.6557 | G Loss: 2.6001\n",
      "Epoch [21/100] | D Loss: 0.6870 | G Loss: 2.6674\n",
      "Epoch [22/100] | D Loss: 0.7231 | G Loss: 2.0966\n",
      "Epoch [23/100] | D Loss: 0.7045 | G Loss: 2.6734\n",
      "Epoch [24/100] | D Loss: 0.6762 | G Loss: 2.7472\n",
      "Epoch [25/100] | D Loss: 0.7125 | G Loss: 2.3092\n",
      "Epoch [26/100] | D Loss: 0.5795 | G Loss: 2.6690\n",
      "Epoch [27/100] | D Loss: 0.7253 | G Loss: 2.1754\n",
      "Epoch [28/100] | D Loss: 0.7183 | G Loss: 2.7377\n",
      "Epoch [29/100] | D Loss: 0.6089 | G Loss: 2.4173\n",
      "Epoch [30/100] | D Loss: 0.7089 | G Loss: 2.7788\n",
      "Epoch [31/100] | D Loss: 0.7824 | G Loss: 2.4726\n",
      "Epoch [32/100] | D Loss: 0.8485 | G Loss: 1.8609\n",
      "Epoch [33/100] | D Loss: 0.9390 | G Loss: 1.4241\n",
      "Epoch [34/100] | D Loss: 0.8505 | G Loss: 2.0201\n",
      "Epoch [35/100] | D Loss: 0.6895 | G Loss: 2.9491\n",
      "Epoch [36/100] | D Loss: 0.5967 | G Loss: 2.9161\n",
      "Epoch [37/100] | D Loss: 0.6391 | G Loss: 2.7580\n",
      "Epoch [38/100] | D Loss: 0.6489 | G Loss: 2.3769\n",
      "Epoch [39/100] | D Loss: 0.7344 | G Loss: 1.9943\n",
      "Epoch [40/100] | D Loss: 0.7637 | G Loss: 2.7060\n",
      "Epoch [41/100] | D Loss: 0.9088 | G Loss: 2.8147\n",
      "Epoch [42/100] | D Loss: 0.9910 | G Loss: 2.0306\n",
      "Epoch [43/100] | D Loss: 0.9818 | G Loss: 1.8605\n",
      "Epoch [44/100] | D Loss: 0.7764 | G Loss: 2.1485\n",
      "Epoch [45/100] | D Loss: 0.6181 | G Loss: 3.2688\n",
      "Epoch [46/100] | D Loss: 0.6745 | G Loss: 2.2978\n",
      "Epoch [47/100] | D Loss: 0.8378 | G Loss: 2.6226\n",
      "Epoch [48/100] | D Loss: 0.6278 | G Loss: 2.6354\n",
      "Epoch [49/100] | D Loss: 0.7909 | G Loss: 2.0951\n",
      "Epoch [50/100] | D Loss: 0.8023 | G Loss: 2.7368\n",
      "Epoch [51/100] | D Loss: 0.9974 | G Loss: 2.0711\n",
      "Epoch [52/100] | D Loss: 0.9389 | G Loss: 2.2705\n",
      "Epoch [53/100] | D Loss: 0.9374 | G Loss: 2.3048\n",
      "Epoch [54/100] | D Loss: 1.0634 | G Loss: 1.8910\n",
      "Epoch [55/100] | D Loss: 1.0308 | G Loss: 2.0229\n",
      "Epoch [56/100] | D Loss: 0.8351 | G Loss: 2.1795\n",
      "Epoch [57/100] | D Loss: 0.9357 | G Loss: 2.6373\n",
      "Epoch [58/100] | D Loss: 0.8409 | G Loss: 2.3663\n",
      "Epoch [59/100] | D Loss: 0.6372 | G Loss: 2.8500\n",
      "Epoch [60/100] | D Loss: 0.8796 | G Loss: 2.2449\n",
      "Epoch [61/100] | D Loss: 0.8302 | G Loss: 2.3250\n",
      "Epoch [62/100] | D Loss: 0.9326 | G Loss: 1.8815\n",
      "Epoch [63/100] | D Loss: 0.8235 | G Loss: 2.1477\n",
      "Epoch [64/100] | D Loss: 1.0615 | G Loss: 1.3769\n",
      "Epoch [65/100] | D Loss: 0.9796 | G Loss: 2.0686\n",
      "Epoch [66/100] | D Loss: 1.0878 | G Loss: 1.7464\n",
      "Epoch [67/100] | D Loss: 1.1013 | G Loss: 1.0405\n",
      "Epoch [68/100] | D Loss: 1.0023 | G Loss: 1.6253\n",
      "Epoch [69/100] | D Loss: 0.9821 | G Loss: 2.5682\n",
      "Epoch [70/100] | D Loss: 0.9114 | G Loss: 2.3595\n",
      "Epoch [71/100] | D Loss: 0.8730 | G Loss: 3.0971\n",
      "Epoch [72/100] | D Loss: 0.9006 | G Loss: 2.2809\n",
      "Epoch [73/100] | D Loss: 0.8771 | G Loss: 2.9719\n",
      "Epoch [74/100] | D Loss: 1.2403 | G Loss: 1.2948\n",
      "Epoch [75/100] | D Loss: 1.1148 | G Loss: 2.0607\n",
      "Epoch [76/100] | D Loss: 0.9118 | G Loss: 1.7924\n",
      "Epoch [77/100] | D Loss: 1.0197 | G Loss: 2.0579\n",
      "Epoch [78/100] | D Loss: 1.0759 | G Loss: 1.5284\n",
      "Epoch [79/100] | D Loss: 1.2930 | G Loss: 1.0216\n",
      "Epoch [80/100] | D Loss: 1.0449 | G Loss: 1.6219\n",
      "Epoch [81/100] | D Loss: 1.1436 | G Loss: 1.4768\n",
      "Epoch [82/100] | D Loss: 0.8212 | G Loss: 2.5369\n",
      "Epoch [83/100] | D Loss: 0.6927 | G Loss: 3.1087\n",
      "Epoch [84/100] | D Loss: 0.8482 | G Loss: 2.7240\n",
      "Epoch [85/100] | D Loss: 1.1844 | G Loss: 1.4242\n",
      "Epoch [86/100] | D Loss: 1.0534 | G Loss: 1.7572\n",
      "Epoch [87/100] | D Loss: 0.9361 | G Loss: 1.9037\n",
      "Epoch [88/100] | D Loss: 0.9827 | G Loss: 1.8000\n",
      "Epoch [89/100] | D Loss: 1.2450 | G Loss: 1.2611\n",
      "Epoch [90/100] | D Loss: 1.1565 | G Loss: 1.3134\n",
      "Epoch [91/100] | D Loss: 1.1955 | G Loss: 1.6806\n",
      "Epoch [92/100] | D Loss: 1.2442 | G Loss: 1.3379\n",
      "Epoch [93/100] | D Loss: 1.1676 | G Loss: 1.3132\n",
      "Epoch [94/100] | D Loss: 1.1941 | G Loss: 1.6460\n",
      "Epoch [95/100] | D Loss: 1.0561 | G Loss: 1.6196\n",
      "Epoch [96/100] | D Loss: 1.1363 | G Loss: 1.8121\n",
      "Epoch [97/100] | D Loss: 1.0662 | G Loss: 1.6133\n",
      "Epoch [98/100] | D Loss: 1.0418 | G Loss: 1.9899\n",
      "Epoch [99/100] | D Loss: 0.9950 | G Loss: 1.6098\n",
      "Epoch [100/100] | D Loss: 1.1269 | G Loss: 1.5600\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "# Make directory for saving generated images\n",
    "os.makedirs(\"generated_images\", exist_ok=True)\n",
    "\n",
    "# Fixed noise to track progress across epochs\n",
    "fixed_noise = torch.randn(64, noise_dim).to(device)\n",
    "\n",
    "def show_and_save_generated_images(images, epoch):\n",
    "    # Reshape and normalize\n",
    "    grid = vutils.make_grid(images.view(-1, 1, 28, 28), normalize=True, nrow=8)\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(f\"Generated Images - Epoch {epoch+1}\")\n",
    "    plt.imshow(grid.permute(1, 2, 0).cpu().numpy())\n",
    "    \n",
    "    # Save to file\n",
    "    filename = f\"generated_images/epoch_{epoch+1:03d}.png\"\n",
    "    plt.savefig(filename, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_idx, (real_images, _) in enumerate(train_loader):\n",
    "        real_images = real_images.view(real_images.size(0), -1)\n",
    "        # Add Gaussian noise (helps D generalize)\n",
    "        real_images += 0.05 * torch.randn_like(real_images)\n",
    "        real_images = real_images.to(device)\n",
    "\n",
    "        real_labels = (torch.ones(real_images.size(0), 1) * 0.9).to(device)  # label smoothing\n",
    "        fake_labels = torch.zeros(real_images.size(0), 1).to(device)\n",
    "\n",
    "        # Train Discriminator\n",
    "        z = torch.randn(real_images.size(0), noise_dim).to(device)\n",
    "        fake_images = G_model(z)\n",
    "\n",
    "        real_outputs = D_model(real_images)\n",
    "        fake_outputs = D_model(fake_images.detach())\n",
    "\n",
    "        d_loss_real = criterion(real_outputs, real_labels)\n",
    "        d_loss_fake = criterion(fake_outputs, fake_labels)\n",
    "        d_loss = d_loss_real + d_loss_fake\n",
    "\n",
    "        D_optimizer.zero_grad()\n",
    "        d_loss.backward()\n",
    "        D_optimizer.step()\n",
    "\n",
    "        # Train Generator\n",
    "        z = torch.randn(real_images.size(0), noise_dim).to(device)\n",
    "        fake_images = G_model(z)\n",
    "        fake_outputs = D_model(fake_images)\n",
    "\n",
    "        g_loss = criterion(fake_outputs, real_labels)\n",
    "\n",
    "        G_optimizer.zero_grad()\n",
    "        g_loss.backward()\n",
    "        G_optimizer.step()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] | D Loss: {d_loss.item():.4f} | G Loss: {g_loss.item():.4f}\")\n",
    "\n",
    "    # Generate & save images with fixed noise\n",
    "    with torch.no_grad():\n",
    "        fake_images = G_model(fixed_noise)\n",
    "    show_and_save_generated_images(fake_images, epoch)\n",
    "\n",
    "print(\"Training complete.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
